{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an assignment for my thinkful data science course - \"Data Cleaning 2\"\n",
    "Raj Prasad\n",
    "May 2019\n",
    "\n",
    "\n",
    "[html version](https://daddyprasad5.github.io/Data_Cleaning_2.html) - with all the code hidden away for a quick read\n",
    "\n",
    "[jupyter notebook version](https://github.com/daddyprasad5/thinkful/blob/master/Data_Cleaning_2.ipynb) - with all the code exposed in an interactive notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "import warnings\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "postgres_user = 'dsbc_student'\n",
    "postgres_pw = '7*.8G9QH21'\n",
    "postgres_host = '142.93.121.174'\n",
    "postgres_port = '5432'\n",
    "postgres_db = 'useducation'\n",
    "\n",
    "engine = create_engine('postgresql://{}:{}@{}:{}/{}'.format(\n",
    "    postgres_user, postgres_pw, postgres_host, postgres_port, postgres_db))\n",
    "\n",
    "used_df = pd.read_sql_query('select * from useducation',con=engine)\n",
    "\n",
    "# no need for an open connection, \n",
    "# as we're only doing a single query\n",
    "engine.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_df.nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for null-like entries in categorical variables\n",
    "u_state = list(used_df.STATE.unique())\n",
    "u_year = list(used_df.YEAR.unique())\n",
    "#pd.DataFrame([u_state, u_year]).transpose()\n",
    "print(u_state)\n",
    "print(u_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1a. Determine all the variable types \n",
    "\n",
    "These are nominal: \n",
    "* PRIMARY_KEY                     1487\n",
    "* STATE                             80\n",
    "\n",
    "This is ordinal:\n",
    "* YEAR                              26\n",
    "\n",
    "These are \n",
    "\n",
    "\n",
    "These are ratio: \n",
    "* ENROLL                          1224\n",
    "* TOTAL_REVENUE                   1274\n",
    "* FEDERAL_REVENUE                 1275\n",
    "* STATE_REVENUE                   1251\n",
    "* LOCAL_REVENUE                   1275\n",
    "* TOTAL_EXPENDITURE               1275\n",
    "* INSTRUCTION_EXPENDITURE         1275\n",
    "* SUPPORT_SERVICES_EXPENDITURE    1275\n",
    "* OTHER_EXPENDITURE               1222\n",
    "* CAPITAL_OUTLAY_EXPENDITURE      1275\n",
    "* GRADES_PK_G                     1261\n",
    "* GRADES_KG_G                     1348\n",
    "* GRADES_4_G                      1340\n",
    "* GRADES_8_G                      1347\n",
    "* GRADES_12_G                     1342\n",
    "* GRADES_1_8_G                    1360\n",
    "* GRADES_9_12_G                   1358\n",
    "* GRADES_ALL_G                    1318\n",
    "* AVG_MATH_4_SCORE                 535\n",
    "* AVG_MATH_8_SCORE                 531\n",
    "* AVG_READING_4_SCORE              532\n",
    "* AVG_READING_8_SCORE              497\n",
    "\n",
    "1b  find the fraction of the missing values for each variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(used_df)\n",
    "cols = used_df.columns\n",
    "num_null = [len(used_df[used_df[col].isnull()]) / n for col in used_df]\n",
    "pd.DataFrame([cols, num_null]).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Notice that the data has a time dimension (year). For this assignment, forget about time and treat all the observations as if they're from the same year. Choose a strategy to deal with the missing values for each variables. For which variables would filling in the missing values with some value make sense? For which might tossing out the records entirely make sense?\n",
    "\n",
    "If there's no order (as year would impose), then I would use the mean or median for all the continuouse variables that are null.  There are too many to throw out any record with  a null. I'll use mean. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "col_list = ['ENROLL', 'TOTAL_REVENUE',\n",
    "       'FEDERAL_REVENUE', 'STATE_REVENUE', 'LOCAL_REVENUE',\n",
    "       'TOTAL_EXPENDITURE', 'INSTRUCTION_EXPENDITURE',\n",
    "       'SUPPORT_SERVICES_EXPENDITURE', 'OTHER_EXPENDITURE',\n",
    "       'CAPITAL_OUTLAY_EXPENDITURE', 'GRADES_PK_G', 'GRADES_KG_G',\n",
    "       'GRADES_4_G', 'GRADES_8_G', 'GRADES_12_G', 'GRADES_1_8_G',\n",
    "       'GRADES_9_12_G', 'GRADES_ALL_G', 'AVG_MATH_4_SCORE', 'AVG_MATH_8_SCORE',\n",
    "       'AVG_READING_4_SCORE', 'AVG_READING_8_SCORE'] \n",
    "\n",
    "for col in col_list:\n",
    "    ave = used_df[col].mean()\n",
    "    used_df[(col+\"v1\")] = used_df[(col)].fillna(ave, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(used_df)\n",
    "cols = used_df.columns\n",
    "num_null = [len(used_df[used_df[col].isnull()]) / n for col in used_df]\n",
    "pd.DataFrame([cols, num_null]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "years = used_df[\"YEAR\"].unique()\n",
    "\n",
    "\n",
    "#loop through each column in the dataframe\n",
    "for col in col_list:\n",
    "    new_col = []\n",
    "    year_ave = []\n",
    "    for y in years: \n",
    "        year_ave.append(np.nanmean(used_df[used_df[\"YEAR\"] == y][col]))\n",
    "    year_ave_dict = dict(zip(years, year_ave))\n",
    "    overall_ave = used_df[col].mean()\n",
    "    for row in used_df.itertuples():\n",
    "        curr_val = getattr(row, col)\n",
    "        curr_year = getattr(row, \"YEAR\")\n",
    "        curr_year_ave = year_ave_dict.get(curr_year)\n",
    "        if np.isnan(curr_val): \n",
    "            if np.isnan(curr_year_ave): \n",
    "                new_col.append(overall_ave)\n",
    "            else: \n",
    "                new_col.append(curr_year_ave)\n",
    "        else: new_col.append(curr_val)\n",
    "    used_df[col + \"v2\"] = new_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(used_df)\n",
    "cols = used_df.columns\n",
    "num_null = [len(used_df[used_df[col].isnull()]) / n for col in used_df]\n",
    "pd.DataFrame([cols, num_null]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_df[\"new_pk\"] = used_df.STATE + used_df.YEAR.map(str)\n",
    "used_df.sort_values(by=\"new_pk\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_used_df = used_df.interpolate()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(new_used_df)\n",
    "cols = new_used_df.columns\n",
    "num_null = [len(new_used_df[new_used_df[col].isnull()]) / n for col in used_df]\n",
    "pd.DataFrame([cols, num_null]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x=\"YEAR\", y=\"TOTAL_REVENUE\", data=new_used_df[used_df.STATE == \"ALABAMA\"], ci=None)\n",
    "sns.lineplot(x=\"YEAR\", y=\"TOTAL_REVENUEv1\", data=used_df[used_df.STATE == \"ALABAMA\"], ci=None)\n",
    "sns.lineplot(x=\"YEAR\", y=\"TOTAL_REVENUEv2\", data=used_df[used_df.STATE == \"ALABAMA\"], ci=None)\n",
    "plt.legend([\"interpolate\", \"total average\", \"average for year\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x=\"YEAR\", y=\"AVG_READING_8_SCORE\", data=new_used_df[used_df.STATE == \"ALABAMA\"], ci=None)\n",
    "sns.lineplot(x=\"YEAR\", y=\"AVG_READING_8_SCOREv1\", data=used_df[used_df.STATE == \"ALABAMA\"], ci=None)\n",
    "sns.lineplot(x=\"YEAR\", y=\"AVG_READING_8_SCOREv2\", data=used_df[used_df.STATE == \"ALABAMA\"], ci=None)\n",
    "plt.legend([\"interpolate\", \"total average\", \"average for year\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x=\"YEAR\", y=\"ENROLL\", data=new_used_df[used_df.STATE == \"ALABAMA\"], ci=None)\n",
    "sns.lineplot(x=\"YEAR\", y=\"ENROLLv1\", data=used_df[used_df.STATE == \"ALABAMA\"], ci=None)\n",
    "sns.lineplot(x=\"YEAR\", y=\"ENROLLv2\", data=used_df[used_df.STATE == \"ALABAMA\"], ci=None)\n",
    "plt.legend([\"interpolate\", \"total average\", \"average for year\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_df.TOTAL_REVENUEv1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_used_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
