{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying Authors with Unsupervised Machine Learning\n",
    "Raj Prasad\n",
    "July 2019\n",
    "\n",
    "[html version](https://daddyprasad5.github.io/predicting_authors_v4.html) - with all the code hidden away for a quick read\n",
    "\n",
    "[jupyter notebook version](https://github.com/daddyprasad5/thinkful/blob/master/predicting_authors_v4.ipynb) - with all the code exposed in an interactive notebook\n",
    "\n",
    "\"Stylometry\" is the science of determining the author of a work whose authorship is uncertain.  I've explored several ways to classify the authorship of american poems.  The dataset contains 10 poems each by 6 authors.   \n",
    "\n",
    "I created some base features using the poems' text: \n",
    "\n",
    "* punctuation frequency\n",
    "* part of speech frequency\n",
    "* stop word frequency\n",
    "* poem length\n",
    "* ratio of unique words\n",
    "* tf/idf glover vectors\n",
    "\n",
    "Then I created several models of different types, trained on different feature vectors. A random-guessing machine would be correct 16% of the time.\n",
    "\n",
    "|Model | Feature set | Correct-classification rate\n",
    "|---|---|---\n",
    "|kmeans | base features | 40%\n",
    "|spectral clustering | base features | 40%\n",
    "|logistic regression | base features | 67%\n",
    "|logistic regression | kmeans & spectral classifications | 6%\n",
    "|logistic regression | base features + kmeans & spectral classifiations | 67%\n",
    "|logistic regression | 10 features chosen by scikit learn's recursive feature elimination | 63%\n",
    "\n",
    "The best model is the logistic regression using the base features directly.  The unsupervised learning features were weaker as solo classifiers and added no value to the logistic regression when included as input features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>poem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>SIENA MI FE', DISFECEMI MAREMMA</td>\n",
       "      <td>AMONG the pickled foetuses and bottled bones,\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>the_age_demanded</td>\n",
       "      <td>VIDE POEM II.\\n\\nFOR this agility chance found...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>ODE_POUR _ELECTION_DE_SON_SEPULCHRE</td>\n",
       "      <td>FOR three years, out of key with his time,\\nHe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>medallion</td>\n",
       "      <td>LUINI in porcelain!\\nThe grand piano\\nUtters a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1920 (MAUBERLEY) I</td>\n",
       "      <td>I.\\n\\nTURNED from the \"eau-forte\\n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   author                                title  \\\n",
       "0       3      SIENA MI FE', DISFECEMI MAREMMA   \n",
       "1       3                     the_age_demanded   \n",
       "2       3  ODE_POUR _ELECTION_DE_SON_SEPULCHRE   \n",
       "3       3                            medallion   \n",
       "4       3                   1920 (MAUBERLEY) I   \n",
       "\n",
       "                                                poem  \n",
       "0  AMONG the pickled foetuses and bottled bones,\\...  \n",
       "1  VIDE POEM II.\\n\\nFOR this agility chance found...  \n",
       "2  FOR three years, out of key with his time,\\nHe...  \n",
       "3  LUINI in porcelain!\\nThe grand piano\\nUtters a...  \n",
       "4              I.\\n\\nTURNED from the \"eau-forte\\n...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read poems, display some of the base data\n",
    "\n",
    "def listdir_nohidden(path):\n",
    "    for f in os.listdir(path):\n",
    "        if not f.startswith('.'):\n",
    "            yield f\n",
    "\n",
    "directory = \"poems/\"\n",
    "authors, titles, poems = ([] for i in range(3))\n",
    "token_counts = defaultdict(Counter)  #used later in creating features\n",
    "author_int = 0\n",
    "nlp = spacy.load('en')     \n",
    "\n",
    "for author in listdir_nohidden(directory):\n",
    "    for title in listdir_nohidden(directory+author):\n",
    "        with open(directory+author+\"/\"+title, 'r') as myfile:\n",
    "            doc = nlp(myfile.read())\n",
    "            authors.append(author)\n",
    "            titles.append(title[:-4])\n",
    "            poems.append(doc.text)\n",
    "            for token in doc:\n",
    "                if token.is_stop:\n",
    "                    token_counts[token.pos][token.orth] += 1\n",
    "\n",
    "# Convert the author strings into numbers, create some dicts for translations\n",
    "unique_authors = set(authors)\n",
    "author_index = range(len(unique_authors))\n",
    "author_dict = dict(zip(unique_authors, author_index))\n",
    "rev_author_dict = dict(zip(author_index, unique_authors))\n",
    "                \n",
    "poems_df = pd.DataFrame({\"author\": [author_dict[a] for a in authors], \"title\": titles, \"poem\": poems})\n",
    "poems_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'robert_frost', 1: 'ts_eliot', 2: 'ralph_waldo_emerson', 3: 'ezra_pound', 4: 'edgar_allen_poe', 5: 'walt_whitman'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5    10\n",
       "4    10\n",
       "3    10\n",
       "2    10\n",
       "1    10\n",
       "0    10\n",
       "Name: author, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#poems by author\n",
    "print(rev_author_dict)\n",
    "poems_df.author.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "guessing the highest probability class all the time would result in a 16% success rate\n"
     ]
    }
   ],
   "source": [
    "#set baseline for evaluating model prediction\n",
    "baseline = int(poems_df.author.value_counts().max()\n",
    "            / poems_df.author.value_counts().sum() * 100) \n",
    "\n",
    "print(\"guessing the highest probability class all the time would result in a {}% success rate\".format(baseline))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#create some features based on punctuation frequency, parts of speech frequency, \n",
    "from collections import Counter\n",
    "import spacy,en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "#create features: count parts of speech occurrences\n",
    "\n",
    "pos = [\"adv\", \"conj\", \"noun\",\"pron\",\"propn\",\"verb\"]\n",
    "periods, words, unique_words, commas, exclamations, semicolons, colons, advs, conjs, nouns, prons, propns, verbs = ([] for i in range(13))\n",
    "\n",
    "    \n",
    "for poem in poems_df.poem: \n",
    "    \n",
    "    tokens = nlp(poem)\n",
    "    \n",
    "    #count punctuations\n",
    "    comma = poem.count(',') \n",
    "    exclamation = poem.count('!')\n",
    "    semicolon= poem.count(';')\n",
    "    colon = poem.count(':')\n",
    "    period = poem.count('.')\n",
    "    \n",
    "    #get percent of all words for each part of speech\n",
    "    c = Counter(([token.pos_ for token in tokens]))\n",
    "    adv = conj = noun = pron = propn = verb = 0\n",
    "    sbase = sum(c.values())\n",
    "    for el, cnt in c.items():\n",
    "        val = (100.0* cnt)/sbase\n",
    "        if el == \"ADV\": adv = val\n",
    "        elif el == \"CONJ\": conj = val\n",
    "        elif el == \"NOUN\": noun = val\n",
    "        elif el == \"PRON\": pron = val\n",
    "        elif el == \"PROPN\": propn = val\n",
    "        elif el == \"VERB\": verb = val\n",
    "        \n",
    "    #append to feature lists\n",
    "    words.append(sbase)\n",
    "    unique_words.append(len(c) / sbase)\n",
    "    advs.append(adv)\n",
    "    conjs.append(conj)\n",
    "    nouns.append(noun)\n",
    "    prons.append(pron/sbase)\n",
    "    propns.append(propn/sbase)\n",
    "    verbs.append(verb/sbase)\n",
    "    commas.append(comma/sbase)\n",
    "    exclamations.append(exclamation/sbase)\n",
    "    semicolons.append(semicolon/sbase)\n",
    "    colons.append(colon/sbase)\n",
    "    periods.append(period/sbase)\n",
    "\n",
    "#add feature lists to the dataframe\n",
    "X=pd.DataFrame()\n",
    "X[\"adv_percent\"] = advs\n",
    "X[\"conj_percent\"] = conjs\n",
    "X[\"noun_percent\"] = nouns\n",
    "X[\"propn_percent\"] = propns\n",
    "X[\"verb_percent\"] = verbs\n",
    "X[\"words_per_poem\"] = words\n",
    "X[\"unique_words_rate\"] = unique_words\n",
    "X[\"commas_rate\"] = commas\n",
    "X[\"exclamations_rate\"] = exclamations\n",
    "X[\"semicolons_rate\"] = semicolons\n",
    "X[\"colons_rate\"] = colons\n",
    "X[\"periods_rate\"] = periods\n",
    "# for word in top_common_words:\n",
    "#     X_bag_of_words_temp[\"top_word_{}_freq\".format(word)] = tcw_freqs[word]\n",
    "\n",
    "#create features sets to later create multiple features for regression\n",
    "punctuation_fs = [\"commas_per_poem\", \"exclamations_per_poem\", \"semicolons_per_poem\", \n",
    "                  \"colons_per_poem\", \"periods_per_poem\"]\n",
    "pos_fs = [\"adv_percent\", \"conj_percent\", \"noun_percent\", \"propn_percent\", \"verb_percent\"] \n",
    "words_fs = [\"words_per_poem\", \"unique_words_per_poem\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#use PCA and tf/idf to create another set of features\n",
    "\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.tfidfmodel import TfidfModel\n",
    "from gensim.matutils import sparse2full\n",
    "from sklearn import linear_model, datasets, metrics\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def keep_token(t):\n",
    "    return (t.is_alpha and \n",
    "            not (t.is_space or t.is_punct or \n",
    "                 t.is_stop or t.like_num))\n",
    "\n",
    "def lemmatize_doc(doc):\n",
    "    return [ t.lemma_ for t in doc if keep_token(t)]\n",
    "\n",
    "docs = [lemmatize_doc(nlp(doc)) for doc in poems_df[\"poem\"].values]\n",
    "docs_dict = Dictionary(docs)\n",
    "docs_dict.filter_extremes(no_below=3, no_above=0.2)\n",
    "docs_dict.compactify()\n",
    "\n",
    "#create tf/idf matrix\n",
    "docs_corpus = [docs_dict.doc2bow(doc) for doc in docs]\n",
    "model_tfidf = TfidfModel(docs_corpus, id2word=docs_dict)\n",
    "docs_tfidf  = model_tfidf[docs_corpus]\n",
    "docs_vecs   = np.vstack([sparse2full(c, len(docs_dict)) for c in docs_tfidf])\n",
    "\n",
    "#get the Glove embedding vector for each TF-IDF term.\n",
    "tfidf_emb_vecs = np.vstack([nlp(docs_dict[i]).vector for i in range(len(docs_dict))])\n",
    "\n",
    "#get a TF-IDF weighted Glove vector summary of each document\n",
    "docs_emb = np.dot(docs_vecs, tfidf_emb_vecs) \n",
    "\n",
    "#create pca components\n",
    "pca = PCA(5) #5 components explains ~90% of the variance\n",
    "docs_pca = pca.fit_transform(docs_emb)\n",
    "\n",
    "#start a features dataframe\n",
    "X_tf_idf = pd.DataFrame()\n",
    "pca_dim = ([[r[col] for r in docs_pca] for col in range(len(docs_pca[0]))])\n",
    "for i, pca_dim in enumerate(docs_pca.transpose()): \n",
    "    X[\"tf_idf_PCA_{}\".format(i)] = pca_dim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#define Xs, Y, and train-test splits for clustering\n",
    "\n",
    "Y = poems_df.author\n",
    "poems_train, poems_test, X_train, X_test, Y_train, Y_test = train_test_split(poems_df, X, Y, test_size=0.25, random_state=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top common words:  ['the', 'and', 'of', 'in', 'a', 'i', 'to', 'with', 'that', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adv_percent</th>\n",
       "      <th>conj_percent</th>\n",
       "      <th>noun_percent</th>\n",
       "      <th>propn_percent</th>\n",
       "      <th>verb_percent</th>\n",
       "      <th>words_per_poem</th>\n",
       "      <th>unique_words_rate</th>\n",
       "      <th>commas_rate</th>\n",
       "      <th>exclamations_rate</th>\n",
       "      <th>semicolons_rate</th>\n",
       "      <th>colons_rate</th>\n",
       "      <th>periods_rate</th>\n",
       "      <th>tf_idf_PCA_0</th>\n",
       "      <th>tf_idf_PCA_1</th>\n",
       "      <th>tf_idf_PCA_2</th>\n",
       "      <th>tf_idf_PCA_3</th>\n",
       "      <th>tf_idf_PCA_4</th>\n",
       "      <th>z_top_word_the_freq</th>\n",
       "      <th>z_top_word_and_freq</th>\n",
       "      <th>z_top_word_of_freq</th>\n",
       "      <th>z_top_word_in_freq</th>\n",
       "      <th>z_top_word_a_freq</th>\n",
       "      <th>z_top_word_i_freq</th>\n",
       "      <th>z_top_word_to_freq</th>\n",
       "      <th>z_top_word_with_freq</th>\n",
       "      <th>z_top_word_that_freq</th>\n",
       "      <th>z_top_word_is_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>7.746479</td>\n",
       "      <td>0</td>\n",
       "      <td>15.492958</td>\n",
       "      <td>0.034715</td>\n",
       "      <td>0.069431</td>\n",
       "      <td>142</td>\n",
       "      <td>0.077465</td>\n",
       "      <td>0.049296</td>\n",
       "      <td>0.007042</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028169</td>\n",
       "      <td>-42.627598</td>\n",
       "      <td>10.355962</td>\n",
       "      <td>8.339205</td>\n",
       "      <td>5.587760</td>\n",
       "      <td>4.795969</td>\n",
       "      <td>-1.452750</td>\n",
       "      <td>-1.695428</td>\n",
       "      <td>-1.573685</td>\n",
       "      <td>-2.227953</td>\n",
       "      <td>0.280649</td>\n",
       "      <td>-1.624403</td>\n",
       "      <td>-2.707871</td>\n",
       "      <td>-6.330648</td>\n",
       "      <td>2.735418</td>\n",
       "      <td>1.536585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>3.338898</td>\n",
       "      <td>0</td>\n",
       "      <td>19.699499</td>\n",
       "      <td>0.008640</td>\n",
       "      <td>0.018395</td>\n",
       "      <td>599</td>\n",
       "      <td>0.023372</td>\n",
       "      <td>0.051753</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026711</td>\n",
       "      <td>0.001669</td>\n",
       "      <td>0.018364</td>\n",
       "      <td>60.046505</td>\n",
       "      <td>6.144707</td>\n",
       "      <td>-3.516366</td>\n",
       "      <td>6.666318</td>\n",
       "      <td>0.234833</td>\n",
       "      <td>1.522923</td>\n",
       "      <td>-0.374475</td>\n",
       "      <td>0.545024</td>\n",
       "      <td>-2.366904</td>\n",
       "      <td>-0.669635</td>\n",
       "      <td>0.377213</td>\n",
       "      <td>-0.339616</td>\n",
       "      <td>1.828311</td>\n",
       "      <td>0.765425</td>\n",
       "      <td>-1.680499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>4.372624</td>\n",
       "      <td>0</td>\n",
       "      <td>17.300380</td>\n",
       "      <td>0.006144</td>\n",
       "      <td>0.019517</td>\n",
       "      <td>526</td>\n",
       "      <td>0.026616</td>\n",
       "      <td>0.096958</td>\n",
       "      <td>0.034221</td>\n",
       "      <td>0.007605</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007605</td>\n",
       "      <td>28.609455</td>\n",
       "      <td>14.834477</td>\n",
       "      <td>-12.066852</td>\n",
       "      <td>0.018187</td>\n",
       "      <td>-1.930606</td>\n",
       "      <td>-0.155028</td>\n",
       "      <td>-0.453922</td>\n",
       "      <td>-3.051876</td>\n",
       "      <td>-1.288748</td>\n",
       "      <td>-1.107541</td>\n",
       "      <td>-1.054551</td>\n",
       "      <td>-0.010942</td>\n",
       "      <td>-3.233552</td>\n",
       "      <td>-0.142379</td>\n",
       "      <td>-0.377763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2.150538</td>\n",
       "      <td>0</td>\n",
       "      <td>16.129032</td>\n",
       "      <td>0.161868</td>\n",
       "      <td>0.046248</td>\n",
       "      <td>93</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.043011</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021505</td>\n",
       "      <td>-49.930099</td>\n",
       "      <td>5.630881</td>\n",
       "      <td>0.033307</td>\n",
       "      <td>5.004325</td>\n",
       "      <td>0.818642</td>\n",
       "      <td>-1.376453</td>\n",
       "      <td>0.889302</td>\n",
       "      <td>7.477792</td>\n",
       "      <td>-0.813327</td>\n",
       "      <td>-0.271212</td>\n",
       "      <td>-1.624403</td>\n",
       "      <td>2.376661</td>\n",
       "      <td>-6.330648</td>\n",
       "      <td>-2.100753</td>\n",
       "      <td>-1.680499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>5.306122</td>\n",
       "      <td>0</td>\n",
       "      <td>18.775510</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>0.033319</td>\n",
       "      <td>245</td>\n",
       "      <td>0.053061</td>\n",
       "      <td>0.151020</td>\n",
       "      <td>0.008163</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>4.633615</td>\n",
       "      <td>2.254403</td>\n",
       "      <td>2.037948</td>\n",
       "      <td>4.091328</td>\n",
       "      <td>2.725576</td>\n",
       "      <td>-0.775043</td>\n",
       "      <td>0.945481</td>\n",
       "      <td>-3.855520</td>\n",
       "      <td>-1.800560</td>\n",
       "      <td>-0.700108</td>\n",
       "      <td>-1.624403</td>\n",
       "      <td>-0.777824</td>\n",
       "      <td>10.292537</td>\n",
       "      <td>-2.100753</td>\n",
       "      <td>0.184097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    adv_percent  conj_percent  noun_percent  propn_percent  verb_percent  words_per_poem  unique_words_rate  commas_rate  exclamations_rate  semicolons_rate  colons_rate  periods_rate  tf_idf_PCA_0  tf_idf_PCA_1  tf_idf_PCA_2  tf_idf_PCA_3  tf_idf_PCA_4  z_top_word_the_freq  z_top_word_and_freq  z_top_word_of_freq  z_top_word_in_freq  z_top_word_a_freq  z_top_word_i_freq  z_top_word_to_freq  z_top_word_with_freq  z_top_word_that_freq  z_top_word_is_freq\n",
       "31     7.746479             0     15.492958       0.034715      0.069431             142           0.077465     0.049296           0.007042         0.000000     0.000000      0.028169    -42.627598     10.355962      8.339205      5.587760      4.795969            -1.452750            -1.695428           -1.573685           -2.227953           0.280649          -1.624403           -2.707871             -6.330648              2.735418            1.536585\n",
       "42     3.338898             0     19.699499       0.008640      0.018395             599           0.023372     0.051753           0.000000         0.026711     0.001669      0.018364     60.046505      6.144707     -3.516366      6.666318      0.234833             1.522923            -0.374475            0.545024           -2.366904          -0.669635           0.377213           -0.339616              1.828311              0.765425           -1.680499\n",
       "34     4.372624             0     17.300380       0.006144      0.019517             526           0.026616     0.096958           0.034221         0.007605     0.000000      0.007605     28.609455     14.834477    -12.066852      0.018187     -1.930606            -0.155028            -0.453922           -3.051876           -1.288748          -1.107541          -1.054551           -0.010942             -3.233552             -0.142379           -0.377763\n",
       "52     2.150538             0     16.129032       0.161868      0.046248              93           0.129032     0.129032           0.064516         0.043011     0.000000      0.021505    -49.930099      5.630881      0.033307      5.004325      0.818642            -1.376453             0.889302            7.477792           -0.813327          -0.271212          -1.624403            2.376661             -6.330648             -2.100753           -1.680499\n",
       "56     5.306122             0     18.775510       0.009996      0.033319             245           0.053061     0.151020           0.008163         0.028571     0.000000      0.028571      4.633615      2.254403      2.037948      4.091328      2.725576            -0.775043             0.945481           -3.855520           -1.800560          -0.700108          -1.624403           -0.777824             10.292537             -2.100753            0.184097"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#build a \"burrows\" word frequency featureset \n",
    "\n",
    "#get all the tokens for the training set and test set\n",
    "tokens_counts = []\n",
    "train_docs = []\n",
    "test_docs = []\n",
    "for poem in poems_train.poem:\n",
    "    doc = nlp(poem)\n",
    "    train_docs.append(doc)\n",
    "    for token in doc:\n",
    "        if token.is_stop:\n",
    "            token_counts[token.pos][token.orth] += 1\n",
    "for poem in poems_test.poem:\n",
    "    doc = nlp(poem)\n",
    "    test_docs.append(doc)\n",
    "    for token in doc:\n",
    "        if token.is_stop:\n",
    "            token_counts[token.pos][token.orth] += 1\n",
    "            \n",
    "#get a list of the top 10 most common words in the training set only\n",
    "common_words = dict()\n",
    "for pos_id, counts in sorted(token_counts.items()):\n",
    "    pos = doc.vocab.strings[pos_id]\n",
    "    for orth_id, count in counts.most_common():\n",
    "        w = doc.vocab.strings[orth_id].lower()\n",
    "        if w in common_words: \n",
    "            common_words[w] = common_words[w] + count\n",
    "        else: \n",
    "            common_words[w] = count\n",
    "\n",
    "top_common_words = sorted(common_words, key=common_words.__getitem__, reverse=True)[:10]\n",
    "print(\"top common words: \", top_common_words)\n",
    "\n",
    "#build a feature for frequency of each top word, in the training and test sets only\n",
    "X_bag_of_words_train = pd.DataFrame()\n",
    "X_bag_of_words_test = pd.DataFrame()\n",
    "tcw_freqs_train = dict()\n",
    "tcw_freqs_test = dict()\n",
    "for word in top_common_words: \n",
    "    tcw_freqs_train[word] = []\n",
    "    tcw_freqs_test[word] = []\n",
    "for doc in train_docs:\n",
    "    sbase = len(doc)\n",
    "    cw_counts = Counter(token.text.lower() for token in doc if token.text.lower() in top_common_words)\n",
    "    for word in top_common_words:\n",
    "        tcw_freqs_train[word].append(cw_counts[word] / sbase * 100)\n",
    "for doc in test_docs:\n",
    "    sbase = len(doc)\n",
    "    cw_counts = Counter(token.text.lower() for token in doc if token.text.lower() in top_common_words)\n",
    "    for word in top_common_words:\n",
    "        tcw_freqs_test[word].append(cw_counts[word] / sbase * 100)\n",
    "\n",
    "for word in top_common_words: \n",
    "    X_bag_of_words_train[\"top_word_{}_freq\".format(word)] = tcw_freqs_train[word]\n",
    "    X_bag_of_words_test[\"top_word_{}_freq\".format(word)] = tcw_freqs_test[word]\n",
    "X_bag_of_words_train.index = poems_train.index\n",
    "X_bag_of_words_test.index = poems_test.index\n",
    "        \n",
    "#build a dictionary (author) of dictionaries (frequency distributions of the most common words) for training set only\n",
    "tw_freq_cols = [\"top_word_{}_freq\".format(word) for word in top_common_words]\n",
    "cols = tw_freq_cols.copy()\n",
    "cols.append(\"author\")\n",
    "burrows = pd.concat([poems_train, X_bag_of_words_train], axis=1).loc[:, cols]\n",
    "burrows = burrows.groupby(by=\"author\").mean()\n",
    "\n",
    "#using just the training set only, find the mean of means and the std of means for each feature (common word), then \n",
    "#find the zscore of each author for each feature and add to the training set and test set\n",
    "bow_fs = []\n",
    "for col in tw_freq_cols:\n",
    "    u_of_us = burrows[col].values.mean()\n",
    "    std_of_means = burrows[col].values.std()\n",
    "    X_train[\"z_{}\".format(col)] = (X_bag_of_words_train[col] - u_of_us) / std_of_means\n",
    "    X_test[\"z_{}\".format(col)] = (X_bag_of_words_test[col] - u_of_us) / std_of_means\n",
    "    bow_fs.append(\"z_{}\".format(col))\n",
    "X_test.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#function to calculate the best predict-class to actual-class alignments for any clustering model\n",
    "import itertools\n",
    "\n",
    "def best_class_alignments(y_pred, y): \n",
    "    y_pred = np.array(y_pred)\n",
    "    y = np.array(y)\n",
    "    ct = pd.crosstab(y_pred, y)\n",
    "    actual_classes = ct.columns\n",
    "    pred_classes = ct.index\n",
    "    pred_perms = list(itertools.permutations(pred_classes))\n",
    "    scores = []\n",
    "    for pred_perm in list(pred_perms):\n",
    "        score = 0\n",
    "        for i, val in enumerate(pred_perm):\n",
    "            score += ct.iloc[i][val]\n",
    "        scores.append(score)\n",
    "    best_score = max(scores)\n",
    "    best_perm = (pred_perms[scores.index(best_score)])\n",
    "    class_dict = dict()\n",
    "    for i, perm in enumerate(best_perm):\n",
    "        class_dict[perm] = actual_classes[i]\n",
    "    return (class_dict, best_score/len(y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#functions to fit clustering models\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import SpectralClustering\n",
    "\n",
    "def cluster_kmeans(fvs_train, y_train, k=6, max_iter=300, n_init=20, tol=.0001, verbose=True):\n",
    "    #fits on the train data and predicts on all the data\n",
    "    km = KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=max_iter,\n",
    "                n_clusters=k, n_init=n_init, n_jobs=None, precompute_distances='auto',\n",
    "                random_state=46, tol=0.0001, verbose=0)\n",
    "    y_pred = km.fit_predict(fvs_train)\n",
    "    if verbose:\n",
    "        ct = pd.crosstab(y_pred, y_train, margins=True)\n",
    "        ct.columns = cols\n",
    "        print(\"k-means clustering:\")\n",
    "        print(ct)\n",
    "    return km, y_pred\n",
    "\n",
    "\n",
    "def cluster_spectral(fvs_train, y_train, k=6, gamma=1.0, n_init=100, n_neighbors=10, verbose=True):\n",
    "    # Declare and fit the model.\n",
    "    sc = SpectralClustering(affinity='rbf', assign_labels='kmeans', coef0=1, degree=3,\n",
    "                            eigen_solver=None, eigen_tol=0.0, gamma=gamma, kernel_params=None,\n",
    "                            n_clusters=k, n_init=n_init, n_jobs=None, n_neighbors=n_neighbors,\n",
    "                            random_state=46)\n",
    "    y_pred = sc.fit_predict(fvs_train)\n",
    "    if verbose:\n",
    "        ct = pd.crosstab(y_pred, y_train, margins=True)\n",
    "        ct.columns = cols\n",
    "        print(\"spectral clustering:\")\n",
    "        print(ct)\n",
    "    return sc, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-means clustering:\n",
      "       robert_frost  ts_eliot  ralph_waldo_emerson  ezra_pound  edgar_allen_poe  walt_whitman  total\n",
      "row_0                                                                                               \n",
      "0                 6         1                    0           5                4             2     18\n",
      "1                 0         0                    0           0                0             1      1\n",
      "2                 0         1                    4           2                1             3     11\n",
      "3                 0         1                    0           0                1             0      2\n",
      "4                 0         0                    1           1                2             0      4\n",
      "5                 2         3                    2           0                0             2      9\n",
      "All               8         6                    7           8                8             8     45\n",
      "best class alignment and percent accurate classification: \n",
      " ({0: 0, 5: 1, 2: 2, 3: 3, 4: 4, 1: 5}, 0.35555555555555557)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spectral clustering:\n",
      "       robert_frost  ts_eliot  ralph_waldo_emerson  ezra_pound  edgar_allen_poe  walt_whitman  total\n",
      "row_0                                                                                               \n",
      "0                 0         0                    0           0                0             1      1\n",
      "2                 0         1                    0           0                0             0      1\n",
      "5                 8         5                    7           8                8             7     43\n",
      "All               8         6                    7           8                8             8     45\n",
      "best class alignment and percent accurate classification: \n",
      " ({5: 0, 2: 1, 0: 2}, 0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/cluster/spectral.py:268: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  n_init=n_init)\n"
     ]
    }
   ],
   "source": [
    "#try several different clustering methods and compare\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "auths = [rev_author_dict[index] for index in range(len(unique_authors))]\n",
    "cols = auths.copy()\n",
    "cols.append(\"total\")\n",
    "\n",
    "km, km_ypred = cluster_kmeans(X_train, Y_train, len(unique_authors))\n",
    "print(\"best class alignment and percent accurate classification: \\n\", best_class_alignments(km_ypred, Y_train))\n",
    "\n",
    "sc, sc_ypred = cluster_spectral(X_train, Y_train, len(unique_authors))\n",
    "print(\"best class alignment and percent accurate classification: \\n\", best_class_alignments(sc_ypred, Y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kmeans performs \"better\" as defined by author identification precision, giving an 20% lift in precision over the base success rate (guessing most populous class all the time), while spectral clustering performs only marginally better than base. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#grid-search of k-means\n",
    "from sklearn import metrics\n",
    "\n",
    "def kmeans_grid_search(fvs_train, y_train, k, max_iters, n_inits, tols):\n",
    "    scores=[]\n",
    "    kms=[]\n",
    "    clusterss=[]\n",
    "    for max_iter in max_iters:\n",
    "        for n_init in n_inits:\n",
    "            for tol in tols:\n",
    "                km, clusters = cluster_kmeans(fvs_train, y_train, k=k, max_iter=max_iter, n_init=n_init, tol=tol, verbose=False)\n",
    "                #scores.append(metrics.silhouette_score(fvs_train, clusters))\n",
    "                best_class, score = best_class_alignments(clusters, y_train)\n",
    "                scores.append(score)\n",
    "                kms.append(km)\n",
    "                clusterss.append(clusters)\n",
    "    return (kms, clusterss, scores)\n",
    "\n",
    "kms, clusterss, scores = kmeans_grid_search(X_train, Y_train, len(unique_authors), \n",
    "                                           max_iters=[100,300,500,1000], \n",
    "                                           n_inits=[1,20,50,100], \n",
    "                                          tols=[1, 0, .1, .01, .001, .0001, .00001, .000001, .0000001])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts of each unique correct classification ratio\n",
      "0.377778    72\n",
      "0.355556    36\n",
      "0.311111    36\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#count of unique correct-classification ratios\n",
    "print(\"counts of each unique correct classification ratio\")\n",
    "print(pd.Series(scores).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tuning did not improve kmeans much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-means clustering on training data:\n",
      "author  0  1  2  3  4  5\n",
      "row_0                   \n",
      "0       6  1  0  5  4  2\n",
      "1       0  1  0  0  1  0\n",
      "2       0  0  4  2  1  3\n",
      "3       0  0  0  0  0  1\n",
      "4       0  0  1  1  2  0\n",
      "5       2  4  2  0  0  2\n",
      "best score 0.37777777777777777\n",
      "class dict {0: 0, 3: 1, 2: 2, 5: 3, 4: 4, 1: 5}\n",
      "k-means clustering on test data:\n",
      "author  0  1  2  3  4  5\n",
      "row_0                   \n",
      "0       1  0  1  1  1  1\n",
      "1       0  0  1  0  0  0\n",
      "2       0  2  0  0  0  0\n",
      "3       0  1  0  0  0  0\n",
      "4       0  0  1  0  1  0\n",
      "5       1  1  0  1  0  1\n",
      "best score 0.4\n",
      "class dict {0: 0, 2: 1, 1: 2, 3: 3, 4: 4, 5: 5}\n"
     ]
    }
   ],
   "source": [
    "# take a look at the best tuned kmeans\n",
    "km = kms[scores.index(max(scores))]\n",
    "km_y_pred = km.fit_predict(X_train)\n",
    "ct = pd.crosstab(km_y_pred, Y_train)\n",
    "print(\"k-means clustering on training data:\")\n",
    "print(ct)\n",
    "class_dict, best_score = best_class_alignments(pd.Series(km_y_pred), Y_train)\n",
    "print(\"best score\", best_score)\n",
    "print(\"class dict\", class_dict)\n",
    "\n",
    "km = kms[scores.index(max(scores))]\n",
    "km_y_test_pred = km.fit_predict(X_test)\n",
    "ct = pd.crosstab(km_y_test_pred, Y_test)\n",
    "print(\"k-means clustering on test data:\")\n",
    "print(ct)\n",
    "class_dict, best_score = best_class_alignments(pd.Series(km_y_test_pred), Y_test)\n",
    "print(\"best score\", best_score)\n",
    "print(\"class dict\", class_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "oddly, kmeans performs better on test data than on the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/cluster/spectral.py:268: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  n_init=n_init)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/cluster/spectral.py:268: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  n_init=n_init)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/cluster/spectral.py:268: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  n_init=n_init)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/cluster/spectral.py:268: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  n_init=n_init)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/cluster/spectral.py:268: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  n_init=n_init)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/cluster/spectral.py:268: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  n_init=n_init)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/cluster/spectral.py:268: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  n_init=n_init)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/cluster/spectral.py:268: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  n_init=n_init)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/cluster/spectral.py:268: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  n_init=n_init)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/cluster/spectral.py:268: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  n_init=n_init)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/cluster/spectral.py:268: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  n_init=n_init)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/cluster/spectral.py:268: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  n_init=n_init)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/cluster/spectral.py:268: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  n_init=n_init)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/cluster/spectral.py:268: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  n_init=n_init)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/cluster/spectral.py:268: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  n_init=n_init)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/cluster/spectral.py:268: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  n_init=n_init)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/cluster/spectral.py:268: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  n_init=n_init)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/cluster/spectral.py:268: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  n_init=n_init)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/cluster/spectral.py:268: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  n_init=n_init)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/cluster/spectral.py:268: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  n_init=n_init)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/cluster/spectral.py:268: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  n_init=n_init)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/cluster/spectral.py:268: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  n_init=n_init)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/cluster/spectral.py:268: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  n_init=n_init)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/cluster/spectral.py:268: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  n_init=n_init)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/cluster/spectral.py:268: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  n_init=n_init)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/cluster/spectral.py:268: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  n_init=n_init)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/cluster/spectral.py:268: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  n_init=n_init)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/cluster/spectral.py:268: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  n_init=n_init)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/cluster/spectral.py:268: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  n_init=n_init)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/cluster/spectral.py:268: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  n_init=n_init)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/cluster/spectral.py:268: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  n_init=n_init)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/cluster/spectral.py:268: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  n_init=n_init)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/cluster/spectral.py:268: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  n_init=n_init)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/cluster/spectral.py:268: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  n_init=n_init)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/cluster/spectral.py:268: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  n_init=n_init)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/cluster/spectral.py:268: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  n_init=n_init)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/cluster/spectral.py:268: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  n_init=n_init)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/cluster/spectral.py:268: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  n_init=n_init)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/cluster/spectral.py:268: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  n_init=n_init)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/cluster/spectral.py:268: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  n_init=n_init)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/cluster/spectral.py:268: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  n_init=n_init)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/cluster/spectral.py:268: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  n_init=n_init)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/cluster/spectral.py:268: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  n_init=n_init)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/cluster/spectral.py:268: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  n_init=n_init)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/cluster/spectral.py:268: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  n_init=n_init)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/cluster/spectral.py:268: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  n_init=n_init)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/cluster/spectral.py:268: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  n_init=n_init)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/cluster/spectral.py:268: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  n_init=n_init)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n"
     ]
    }
   ],
   "source": [
    "#tuning spectral clustering\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn import metrics\n",
    "\n",
    "#def cluster_spectral(fvs_train, y_train, k, gamma=1.0, n_init=100, n_neighbors=10, verbose=True)\n",
    "\n",
    "def spectral_grid_search(fvs_train, y_train, k, gammas, n_inits, n_neighbors=10):\n",
    "    scores=[]\n",
    "    scs=[]\n",
    "    clusterss=[]\n",
    "    for gamma in gammas:\n",
    "        for n_init in n_inits:\n",
    "            for n_neighbor in n_neighbors:\n",
    "                sc, clusters = cluster_spectral(fvs_train, y_train, k, gamma=gamma, n_init=n_init, n_neighbors=n_neighbor, verbose=False)\n",
    "                #scores.append(metrics.silhouette_score(fvs_train, clusters))\n",
    "                best_class, score = best_class_alignments(clusters, y_train)\n",
    "                scores.append(score)\n",
    "                scs.append(sc)\n",
    "                clusterss.append(clusters)\n",
    "    return (scs, clusterss, scores)\n",
    "\n",
    "scs, clusterss, scores = spectral_grid_search(X_train, Y_train, len(unique_authors),\n",
    "                                              gammas=[.01, .1, 9, 1, 10],\n",
    "                                              n_inits=[1, 20, 50, 100],\n",
    "                                              n_neighbors=[3, 7, 10, 15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spectral clustering on training data:\n",
      "author  0  1  2  3  4  5\n",
      "row_0                   \n",
      "0       0  0  0  0  0  1\n",
      "1       4  2  1  1  5  3\n",
      "2       2  4  6  5  3  3\n",
      "3       1  0  0  0  0  1\n",
      "4       0  0  0  1  0  0\n",
      "5       1  0  0  1  0  0\n",
      "best score 0.3111111111111111\n",
      "class dict {1: 0, 4: 1, 2: 2, 5: 3, 3: 4, 0: 5}\n",
      "spectral clustering on test data:\n",
      "author  0  1  2  3  4  5\n",
      "row_0                   \n",
      "0       1  0  3  1  1  0\n",
      "1       1  0  0  0  1  1\n",
      "2       0  1  0  0  0  0\n",
      "3       0  1  0  1  0  1\n",
      "4       0  1  0  0  0  0\n",
      "5       0  1  0  0  0  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/spectral_embedding_.py:237: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score 0.4\n",
      "class dict {2: 0, 0: 1, 1: 2, 3: 3, 4: 4, 5: 5}\n"
     ]
    }
   ],
   "source": [
    "# take a look at the best tuned spectral clustering model\n",
    "sc = scs[scores.index(max(scores))]\n",
    "sc_y_pred = sc.fit_predict(X_train)\n",
    "ct = pd.crosstab(sc_y_pred, Y_train)\n",
    "print(\"spectral clustering on training data:\")\n",
    "print(ct)\n",
    "class_dict, best_score = best_class_alignments(pd.Series(sc_y_pred), Y_train)\n",
    "print(\"best score\", best_score)\n",
    "print(\"class dict\", class_dict)\n",
    "\n",
    "sc_y_test_pred = sc.fit_predict(X_test)\n",
    "ct = pd.crosstab(sc_y_test_pred, Y_test)\n",
    "print(\"spectral clustering on test data:\")\n",
    "print(ct)\n",
    "class_dict, best_score = best_class_alignments(pd.Series(sc_y_test_pred), Y_test)\n",
    "print(\"best score\", best_score)\n",
    "print(\"class dict\", class_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tuning made a big difference for the spectral clustering model.oddly, spectral clustering performs better on test data than on the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kmeans</th>\n",
       "      <th>spectral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   kmeans  spectral\n",
       "0       2         2\n",
       "1       4         4\n",
       "2       5         2\n",
       "3       2         3\n",
       "4       5         1"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a feature set made up of the kmeans and spectral clustering cluster assignments\n",
    "\n",
    "X_cl_train = pd.DataFrame({\"kmeans\": km_y_pred, \"spectral\": sc_y_pred})\n",
    "X_cl_test = pd.DataFrame({\"kmeans\": km_y_test_pred, \"spectral\": sc_y_test_pred})\n",
    "\n",
    "X_cl_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression using underlying features directly:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.40      0.57         5\n",
      "           1       0.50      1.00      0.67         2\n",
      "           2       0.67      0.67      0.67         3\n",
      "           3       0.50      0.33      0.40         3\n",
      "           4       0.50      1.00      0.67         1\n",
      "           5       0.00      0.00      0.00         1\n",
      "\n",
      "   micro avg       0.53      0.53      0.53        15\n",
      "   macro avg       0.53      0.57      0.50        15\n",
      "weighted avg       0.67      0.53      0.54        15\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression using unsupervised features only:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.00      0.00      0.00         4\n",
      "           2       0.00      0.00      0.00         3\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.25      0.50      0.33         2\n",
      "           5       0.17      0.50      0.25         2\n",
      "\n",
      "   micro avg       0.13      0.13      0.13        15\n",
      "   macro avg       0.07      0.17      0.10        15\n",
      "weighted avg       0.06      0.13      0.08        15\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression using both base and unsupervised features:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.40      0.57         5\n",
      "           1       0.50      1.00      0.67         2\n",
      "           2       0.67      0.67      0.67         3\n",
      "           3       0.50      0.33      0.40         3\n",
      "           4       0.50      1.00      0.67         1\n",
      "           5       0.00      0.00      0.00         1\n",
      "\n",
      "   micro avg       0.53      0.53      0.53        15\n",
      "   macro avg       0.53      0.57      0.50        15\n",
      "weighted avg       0.67      0.53      0.54        15\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "###### fit on the base features (used for clustering) for comparison\n",
    "\n",
    "#logistic_base = linear_model.LogisticRegression(solver='newton-cg', tol=30, multi_class='multinomial')\n",
    "logistic_base = linear_model.LogisticRegressionCV(max_iter=1000, multi_class=\"multinomial\")\n",
    "\n",
    "logistic_base.fit(X_train, Y_train)\n",
    "Y_pred_base = logistic_base.predict(X_test)\n",
    "\n",
    "print(\"Logistic regression using underlying features directly:\\n%s\\n\" % (\n",
    "    metrics.classification_report(Y_pred_base, Y_test)))\n",
    "\n",
    "#fit the logistic model on the clusters-as-features and on the underlying features and compare.\n",
    "from sklearn import linear_model, datasets, metrics\n",
    "\n",
    "#fit on the clusters-as-features\n",
    "#logistic = linear_model.LogisticRegression(solver='newton-cg', tol=1, multi_class='multinomial')\n",
    "logistic = linear_model.LogisticRegressionCV(max_iter=1000, multi_class=\"multinomial\")\n",
    "\n",
    "logistic.fit(X_cl_train, Y_train)\n",
    "Y_pred = logistic.predict(X_cl_test)\n",
    "\n",
    "print(\"Logistic regression using unsupervised features only:\\n%s\\n\" % (\n",
    "    metrics.classification_report(Y_test, Y_pred)))\n",
    "\n",
    "#fit on all the features - base and the unsupervised features\n",
    "\n",
    "X_combined_train = pd.concat([X_cl_train.reset_index(drop=True), X_train.reset_index(drop=True)],axis=1)\n",
    "X_combined_test = pd.concat([X_cl_test.reset_index(drop=True), X_test.reset_index(drop=True)],axis=1)\n",
    "\n",
    "#logistic_base = linear_model.LogisticRegression(solver='newton-cg', tol=30, multi_class='multinomial')\n",
    "logistic_base = linear_model.LogisticRegressionCV(max_iter=1000, multi_class=\"multinomial\")\n",
    "\n",
    "logistic_base.fit(X_combined_train, Y_train)\n",
    "Y_pred_combined = logistic_base.predict(X_combined_test)\n",
    "\n",
    "print(\"Logistic regression using both base and unsupervised features:\\n%s\\n\" % (\n",
    "    metrics.classification_report(Y_pred_combined, Y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True False  True False False False False False False False False False\n",
      " False False False False  True  True False  True  True  True False  True\n",
      "  True  True False False False]\n",
      "[ 1 10  1 20  4 12 18 11 15 13 17 16 19 14  9  7  1  1  3  1  1  1  8  1\n",
      "  1  1  6  5  2]\n",
      "Logistic regression using a subset of the features:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         8\n",
      "           1       1.00      1.00      1.00         6\n",
      "           2       1.00      1.00      1.00         7\n",
      "           3       1.00      1.00      1.00         8\n",
      "           4       1.00      1.00      1.00         8\n",
      "           5       1.00      1.00      1.00         8\n",
      "\n",
      "   micro avg       1.00      1.00      1.00        45\n",
      "   macro avg       1.00      1.00      1.00        45\n",
      "weighted avg       1.00      1.00      1.00        45\n",
      "\n",
      "\n",
      "Logistic regression using a subset of the features:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      1.00      0.57         2\n",
      "           1       1.00      0.50      0.67         4\n",
      "           2       0.67      0.67      0.67         3\n",
      "           3       0.33      0.50      0.40         2\n",
      "           4       1.00      0.50      0.67         2\n",
      "           5       0.00      0.00      0.00         2\n",
      "\n",
      "   micro avg       0.53      0.53      0.53        15\n",
      "   macro avg       0.57      0.53      0.50        15\n",
      "weighted avg       0.63      0.53      0.53        15\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's reduct the number of features - simplify the logistic regression model\n",
    "from sklearn import datasets\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# create a base classifier used to evaluate a subset of attributes\n",
    "model = linear_model.LogisticRegressionCV(max_iter=5000, multi_class=\"multinomial\", cv=5)\n",
    "#model.fit(X_combined_train, Y_train)\n",
    "#print(model.scores_)\n",
    "#Y_pred_train = model.predict(X_combined_train)\n",
    "#Y_pred_test = model.predict(X_combined_test)\n",
    "rfe = RFE(model, 10)\n",
    "rfe = rfe.fit(X_combined_train, Y_train)\n",
    "# summarize the selection of the attributes\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)\n",
    "\n",
    "rfe.estimator_.fit(X_combined_train, Y_train)\n",
    "Y_pred_train = rfe.estimator_.predict(X_combined_train)\n",
    "Y_pred_test = rfe.estimator_.predict(X_combined_test)\n",
    "\n",
    "print(\"Logistic regression using a subset of the features:\\n%s\\n\" % (\n",
    "    metrics.classification_report(Y_train, Y_pred_train)))\n",
    "\n",
    "\n",
    "print(\"Logistic regression using a subset of the features:\\n%s\\n\" % (\n",
    "    metrics.classification_report(Y_test, Y_pred_test)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                  kmeans\n",
       "2             adv_percent\n",
       "16           tf_idf_PCA_2\n",
       "17           tf_idf_PCA_3\n",
       "19    z_top_word_the_freq\n",
       "20    z_top_word_and_freq\n",
       "21     z_top_word_of_freq\n",
       "23      z_top_word_a_freq\n",
       "24      z_top_word_i_freq\n",
       "25     z_top_word_to_freq\n",
       "Name: cols, dtype: object"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#these 10 top features perform mearly as well as the full set...\n",
    "included = pd.Series(rfe.ranking_ == True)\n",
    "X_combined_train.columns[included.index[included]]\n",
    "impt_features = pd.DataFrame({\"cols\": X_combined_train.columns, \"include\": rfe.ranking_ == True})\n",
    "impt_features = impt_features[impt_features.include == True]\n",
    "impt_features.cols\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
