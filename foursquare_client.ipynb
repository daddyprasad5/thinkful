{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "foursquare_client.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6hesrCqszIu",
        "colab_type": "text"
      },
      "source": [
        "# Spark Streaming Four Square Challenge - Stream Reading Notebook\n",
        "Raj Prasad\n",
        "July 2019\n",
        "\n",
        "[html version](https://daddyprasad5.github.io/foursquare_client.html) \n",
        "\n",
        "[jupyter notebook version](https://github.com/daddyprasad5/thinkful/blob/master/foursquare_client.ipynb) \n",
        "\n",
        "The goal of this exercise is to create a stream of foursquare trending venues by calling the foursquare APIs and storing the output into files in my google drive.  \n",
        "\n",
        "Then [another notebook](https://github.com/daddyprasad5/thinkful/blob/master/foursquare_streaming_challenge.ipynb) reads that stream and displays data from it - nothing fancy just the print of the dataframe.  \n",
        "\n",
        "I've got [another interesting version](https://daddyprasad5.github.io/interactive_gmaps_and_four_square.html) of this that uses Jupyter Widgets to allow the notebook user to pick a city, then collects the foursquare trending venues from the foursquare API, and displays the locations of those venues on a google map.   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClNS8tH5scU7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "dd32bd44-cbed-445e-f39b-02380cb3df64"
      },
      "source": [
        "# Point Colaboratory to Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pu8x5Xl8tDP1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#imports\n",
        "import requests\n",
        "import json\n",
        "import datetime\n",
        "from time import sleep\n",
        "\n",
        "#set constants\n",
        "LOG_PATH = \"/content/gdrive/My Drive/Colab Datasets/foursquare_logs/foursquare_trending\"\n",
        "KEY_FILE = \"/content/gdrive/My Drive/Colab Datasets/gookey.txt\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74FXaOKI3Oll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#this is for simulating a continuous stream\n",
        "#it will drop one file (one city) every 3 seconds for about 12 seconds and then stop\n",
        "\n",
        "locs = [\"New York City\", \"San Francisco\", \"Paris\", \"London\"]\n",
        "\n",
        "#should be \"while True\" but I don't want to eat up my rate count by accident\n",
        "for i in range(3):\n",
        "    for loc in locs:\n",
        "      trending_api = f\"https://api.foursquare.com/v2/venues/trending?near='{loc}'&limit=10&radius=2000&client_id=VF5BPQB0PA5NCWMX0J53UE4IVTGHJSNZ5BJFFFNFPQXSLNFG&client_secret=SNQTNEXKJAHFXA11EXTWUDG13GGL4P2B5JMCPM21XJJOQ3SY&v=20190724\"\n",
        "      req = requests.get(trending_api)\n",
        "      response = req.json()\n",
        "      names = []\n",
        "      locations = []\n",
        "\n",
        "      #the API occasionally will return an error - seems a bit flaky...\n",
        "      if response[\"meta\"][\"code\"] == 400: #error on request - move on to next iteration\n",
        "        print('got an error...')\n",
        "        break\n",
        "      \n",
        "      for v in response[\"response\"][\"venues\"]:\n",
        "        names.append(v[\"name\"])\n",
        "        locations.append((v[\"location\"][\"lat\"], v[\"location\"][\"lng\"]))\n",
        "\n",
        "      trending_venues = {\"city\":loc, \"names\":names, \"locations\": locations}\n",
        "\n",
        "      now = datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S')  \n",
        "      fname = LOG_PATH+loc+'-'+now+'.json'\n",
        "      with open(fname, 'w') as f:  # writing JSON object\n",
        "        json.dump(trending_venues, f)\n",
        "\n",
        "      with open(fname, 'r') as f: \n",
        "        venues = json.load(f)\n",
        "      sleep(5)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJJWMCmp-MsN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}